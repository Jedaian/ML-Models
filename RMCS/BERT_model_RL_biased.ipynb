{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQP__9ewHcIC"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from gym import spaces\n",
        "from transformers import BertTokenizerFast\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizerFast, DistilBertForSequenceClassification\n",
        "from torch.distributions import Categorical\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HV4oXM87HgrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelingEnv(gym.Env):\n",
        "  def __init__(self, instances, labels):\n",
        "    super(LabelingEnv, self).__init__()\n",
        "    self.instances = instances\n",
        "    self.labels = labels\n",
        "    self.current_instance = 0\n",
        "    self.tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "    encoded = self.tokenizer([self.instances[self.current_instance]], return_tensors='pt', padding='max_length', truncation=True, max_length=64)\n",
        "\n",
        "    #define the output of the model\n",
        "    self.action_space = spaces.Discrete(2)\n",
        "    self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(1, 64))\n",
        "\n",
        "  def step(self, action):\n",
        "    reward = 1 if action == self.labels[self.current_instance] else -1\n",
        "    self.current_instance += 1\n",
        "    done = self.current_instance == len(self.instances)\n",
        "    if done:\n",
        "      next_state = None\n",
        "    else:\n",
        "        encoded = self.tokenizer([self.instances[self.current_instance]], return_tensors='pt', padding='max_length', truncation=True, max_length=64)\n",
        "        next_state = { 'input_ids': encoded['input_ids'], 'attention_mask': encoded['attention_mask'] }\n",
        "    return next_state, reward, done\n",
        "\n",
        "\n",
        "  def reset(self):\n",
        "    self.current_instance = 0\n",
        "    encoded = self.tokenizer([self.instances[self.current_instance]], return_tensors='pt', padding='max_length', truncation=True, max_length=64)\n",
        "    return { 'input_ids': encoded['input_ids'], 'attention_mask': encoded['attention_mask'] }"
      ],
      "metadata": {
        "id": "77nbN-PSHia2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "x6GPAFJTHjCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading model from BERT\n",
        "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased') # 2 labels: Slang, No Slang\n",
        "tokenizer = BertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "#set up an optimizer\n",
        "optimizer = Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/BERT Models/Dataset/mergedData.csv') #the file directory\n",
        "df.drop_duplicates(subset = ['sentence'], inplace = True)\n",
        "\n",
        "instances = df['sentence'].tolist()\n",
        "labels = df['label'].tolist()\n",
        "\n",
        "#custom envinronment\n",
        "env = LabelingEnv(instances, labels)"
      ],
      "metadata": {
        "id": "U4CGnd7SHkao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "n = 50 #number of epochs\n",
        "model.train()\n",
        "all_rewards = []\n",
        "for epoch in tqdm(range(n), desc = 'Epochs'):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  epoch_rewards = []\n",
        "  pbar = tqdm(total=len(env.instances), desc=f'Epoch {epoch + 1}', leave=False)\n",
        "  while not done:\n",
        "    if state is not None:\n",
        "      state = {k: v.to(device) for k, v in state.items()}\n",
        "      outputs = model(**state)\n",
        "\n",
        "      #softmax for model output\n",
        "      probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "\n",
        "      #sampling action from the probabilities\n",
        "      dist = Categorical(probs[0])\n",
        "      action = dist.sample()\n",
        "\n",
        "      #train in the environment\n",
        "      new_state, reward, done = env.step(action.item())\n",
        "      epoch_rewards.append(reward)\n",
        "\n",
        "      loss = -dist.log_prob(action) * reward\n",
        "\n",
        "      #backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      #updating the state\n",
        "      state = new_state if new_state is not None else None\n",
        "\n",
        "      pbar.update(1)\n",
        "    else:\n",
        "      break\n",
        "  pbar.close()\n",
        "  all_rewards.append(np.sum(epoch_rewards))\n",
        "  print(f'\\nEpoch {epoch + 1}: Total rewards {np.sum(epoch_rewards)}')"
      ],
      "metadata": {
        "id": "N5rvBjL9Hlss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def moving_avg(a, n = 10):\n",
        "  temp = np.cumsum(a, dtype = float)\n",
        "  temp[n:] = temp[n:] - temp[:-n]\n",
        "  return temp[n - 1:] / n\n",
        "\n",
        "moving_avg_rewards = moving_avg(all_rewards, 3)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Total Rewards per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Total Rewards\")\n",
        "plt.plot(all_rewards, label='Rewards')\n",
        "plt.plot(range(len(moving_avg_rewards)), moving_avg_rewards, label='Moving Average Rewards')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GVOajFHNHnZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('/content/drive/MyDrive/BERT Models/BERT RL/model')\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/BERT Models/BERT RL/tokenizer')\n",
        "import pickle\n",
        "\n",
        "with open(\"/content/drive/MyDrive/BERT Models/BERT RL/instances\", \"wb\") as f:\n",
        "    pickle.dump(instances, f)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/BERT Models/BERT RL/labels\", \"wb\") as f:\n",
        "    pickle.dump(labels, f)\n"
      ],
      "metadata": {
        "id": "stU1tTRRHpQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, DistilBertForSequenceClassification\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/BERT Models/BERT RL/model'\n",
        "tokenizer_dir = '/content/drive/MyDrive/BERT Models/BERT RL/tokenizer'\n",
        "\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_dir)\n",
        "tokenizer = BertTokenizerFast.from_pretrained(tokenizer_dir)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/BERT Models/Dataset/mergedDataTest.csv', delimiter = ';')\n",
        "\n",
        "#testing and validation datas\n",
        "instances = list(data['sentence'])\n",
        "true_labels = list(data['label'])\n",
        "\n",
        "inputs = tokenizer(instances, return_tensors='pt', padding='max_length', truncation=True, max_length=64)\n",
        "inputs = {key: val for key, val in inputs.items() if key != 'token_type_ids'}\n",
        "\n",
        "#predicting label\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "predicted_labels = torch.argmax(probs, dim=-1)\n",
        "confidence_scores, _ = torch.max(probs, dim=-1)\n",
        "confidence_scores = confidence_scores.tolist()\n",
        "\n",
        "accuracy = accuracy_score(true_labels, predicted_labels.tolist())"
      ],
      "metadata": {
        "id": "kPUYovh6HsFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, instance in enumerate(instances):\n",
        "  prediction = 'Slang' if predicted_labels[i].item() == 1 else 'No Slang'\n",
        "  is_correct = \"Correct\" if predicted_labels[i].item() == true_labels[i] else \"Incorrect\"\n",
        "  print(f\"Text: {instance}\")\n",
        "  print(f\"Predicted label: {prediction}\")\n",
        "  print(f\"Prediction is: {is_correct}\")\n",
        "  print(f\"Confidence score: {confidence_scores[i]}\")  # no need for .item() here\n",
        "  print(\"\\n\")\n",
        "\n",
        "print(f\"Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "9hmZcSNTHu_j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}